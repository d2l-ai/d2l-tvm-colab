{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following additional libraries are needed to run this\n",
    "notebook. Note that running on Colab is experimental, please report a Github\n",
    "issue if you have any problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/d2l-ai/d2l-tvm\n",
    "!pip install https://tvm-repo.s3-us-west-2.amazonaws.com/cuda10.0-llvm6.0/tvm-0.6.dev0-cp36-cp36m-linux_x86_64.whl https://tvm-repo.s3-us-west-2.amazonaws.com/cuda10.0-llvm6.0/topi-0.6.dev0-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index and Shape Expressions\n",
    "\n",
    "You already know that a shape can be a tuple of symbols such as `(n, m)` and the elements can be accessed via indexing, e.g. `a[i, j]`. In practice, both shapes and indices may be computed through complex expressions. We will go through several examples in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2ltvm\n",
    "import numpy as np\n",
    "import tvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Transpose\n",
    "\n",
    "Our first example is matrix transpose `a.T`, in which we access `a`'s elements by columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "produce b {\n",
       "  for (i, 0, m) {\n",
       "    for (j, 0, n) {\n",
       "      b[((i*stride) + (j*stride))] = a[((j*stride) + (i*stride))]\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = tvm.var('n')\n",
    "m = tvm.var('m')\n",
    "A = tvm.placeholder((n, m), name='a')\n",
    "B = tvm.compute((m, n), lambda i, j: A[j, i], 'b')\n",
    "s = tvm.create_schedule(B.op)\n",
    "tvm.lower(s, [A, B], simple_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the 2-D index, e.g. `b[i,j]` are collapsed to the 1-D index `b[((i*n) + j)]` to follow the C convention.\n",
    "\n",
    "Now verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "21"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11.]]\n",
      "[[ 0.  4.  8.]\n",
      " [ 1.  5.  9.]\n",
      " [ 2.  6. 10.]\n",
      " [ 3.  7. 11.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(12, dtype='float32').reshape((3, 4))\n",
    "b = np.empty((4, 3), dtype='float32')\n",
    "a, b = tvm.nd.array(a), tvm.nd.array(b)\n",
    "\n",
    "mod = tvm.build(s, [A, B])\n",
    "mod(a, b)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "\n",
    "Next let's use expressions for indexing. The following code block reshapes a 2-D array `a` (`n` by `m` as defined above) to 1-D (just like `a.reshape(-1)` in NumPy). Note how we convert the 1-D index `i` to the 2-D index `[i//m, i%m]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "28"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "produce b {\n",
       "  for (i, 0, (m*n)) {\n",
       "    b[i] = a[((floordiv(i, m)*stride) + (floormod(i, m)*stride))]\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = tvm.compute((m*n, ), lambda i: A[i//m, i%m], name='b')\n",
    "s = tvm.create_schedule(B.op)\n",
    "tvm.lower(s, [A, B], simple_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since an $n$-D array is essentially listed in the memory as a 1-D array, the generated code does not rearrange the data sequence, but it simplifies the index expression from 2-D (`(i//m)*m + i%m`) to 1-D (`i`) to improve the efficiency.\n",
    "\n",
    "We can implement a general 2-D reshape function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "31"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "produce b {\n",
       "  for (i, 0, p) {\n",
       "    for (j, 0, q) {\n",
       "      b[((i*stride) + (j*stride))] = a[((floordiv(((i*q) + j), m)*stride) + (floormod(((i*q) + j), m)*stride))]\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, q = tvm.var('p'), tvm.var('q')\n",
    "B = tvm.compute((p, q), lambda i, j: A[(i*q+j)//m, (i*q+j)%m], name='b')\n",
    "s = tvm.create_schedule(B.op)\n",
    "tvm.lower(s, [A, B], simple_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When testing the results, we should be aware that we put no constraint on the output shape, which can have an arbitrary shape `(p, q)`, and therefore TVM will not be able to check if $qp = nm$ for us. For example, in the following example we created a `b` with size (20) larger than `a` (12), then only the first 12 elements in `b` are from `a`, others are uninitialized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  1.0000000e+00  2.0000000e+00  3.0000000e+00]\n",
      " [ 4.0000000e+00  5.0000000e+00  6.0000000e+00  7.0000000e+00]\n",
      " [ 8.0000000e+00  9.0000000e+00  1.0000000e+01  1.1000000e+01]\n",
      " [-1.5077071e+38  4.5651501e-41  1.5834673e-43  0.0000000e+00]\n",
      " [ 1.5631467e-03  3.0687035e-41  1.4012985e-45  0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "mod = tvm.build(s, [A, B])\n",
    "a = np.arange(12, dtype='float32').reshape((3,4))\n",
    "b = np.zeros((5, 4), dtype='float32')\n",
    "a, b = tvm.nd.array(a), tvm.nd.array(b)\n",
    "\n",
    "mod(a, b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing\n",
    "\n",
    "Now let's consider a special slicing operator `a[bi::si, bj::si] ` where `bi`, `bj`, `si` and `sj` can be specified later. Now the output shape needs to be computed based on the arguments. In addition, we need to pass the variables `bi`, `bj`, `si` and `sj` as arguments when compiling the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi, bj, si, sj = [tvm.var(name) for name in ['bi', 'bj', 'si', 'sj']]\n",
    "B = tvm.compute(((n-bi)//si, (m-bj)//sj), lambda i, j: A[i*si+bi, j*sj+bj], name='b')\n",
    "s = tvm.create_schedule(B.op)\n",
    "mod = tvm.build(s, [A, B, bi, si, bj, sj])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test two cases to verify the correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tvm.nd.array(np.empty((1, 3), dtype='float32'))\n",
    "mod(a, b, 1, 2, 1, 1)\n",
    "np.testing.assert_equal(b.asnumpy(), a.asnumpy()[1::2, 1::1])\n",
    "\n",
    "b = tvm.nd.array(np.empty((1, 2), dtype='float32'))\n",
    "mod(a, b, 2, 1, 0, 2)\n",
    "np.testing.assert_equal(b.asnumpy(), a.asnumpy()[2::1, 0::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Both shape dimensions and indices can be expressions with variables.\n",
    "- If a variable doesn't only appear in the shape tuple, we need to pass it as an argument when compiling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}